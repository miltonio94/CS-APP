#+title: Chapter 1: A tour of computer systems

* Table of content :toc:
- [[#11-information-is-bits--context][1.1 Information is bits + Context]]
- [[#12-programs-are-translated-by-other-programs-into-different-forms][1.2 Programs are translated by other programs into different forms]]
- [[#13-it-pays-to-understand-how-compilation-systems-work][1.3 It pays to understand how compilation systems work]]
- [[#14-processors-read-and-interpret-instructions-stored-in-memory][1.4 Processors read and interpret instructions stored in memory]]
  - [[#141-hardware-organisation-of-a-system][1.4.1 Hardware organisation of a system]]
  - [[#142-running-the-hello-world-program][1.4.2 Running the hello world program]]
- [[#15-caches-matter][1.5 Caches matter]]
- [[#16-storage-devices-form-a-hierarchy][1.6 Storage devices form a hierarchy]]
- [[#17-the-operating-system-manages-the-hardware][1.7 The operating system manages the hardware]]
  - [[#171-processes][1.7.1 Processes]]
  - [[#172-threads][1.7.2 Threads]]
  - [[#173-virtual-memory][1.7.3 Virtual memory]]
  - [[#174-files][1.7.4 Files]]
- [[#18-systems-communicate-with-other-systems-using-networks][1.8 Systems communicate with other systems using networks]]
- [[#19-important-themes][1.9 Important themes]]
  - [[#amdahls-law][Amdahl's law]]

* 1.1 Information is bits + Context
The hello world program from K&R book will be the starting point.
#+begin_src c
#include <<stdio.h>

int main(){
  printf("hello world\n");
  return 0;
}
#+end_src
Our program starts as a source file (or source program) that is created by the programmer with an editor and saved with the ~.c~ extension. The code is a sequence of bits, each represented by either a 1 or a 0, organised in 8-bit chunks called bytes. Each one of these bytes represents a character in the program.

Most computers represent text character using the ASCII standards that represents each character as a unique byte-size integer. For example, here's our hello world program represented by ASCII.

#+CAPTION:The ASCI text representation of hello world
[[./imgs/figure1.2.png]]

The hello world program is stored in a file as a sequence of bytes. Each byte represents a integer value that corresponds to a character. As an example the first character is stored as the value 35 which corresponds to the character ~#~. The second value is 105 which corresponds to the character ~i~ and so on. One thing of note is that each line is terminated by the invisible character ~\n~ which is represented by the integer value 10. Files such as the one that stores our hello world program and that consist of ASCII characters are known as text files. All other files are known as binary files.

The representation of our hello world program above illustrates a fundamental idea: All information in a system, this includes files, programs, data stored in memory, and data transferred across a network, are all represented as bits. The only thing that differentiates them is the context that they are viewed in. In one context the same sequence of bytes might represent a character string, in another an integer, or a floating point number or even a machine instruction.

Programmers need to understand machine representation of numbers because they are not the same as integers and real numbers. The are finite approximations that can behave in unexpected ways.
* 1.2 Programs are translated by other programs into different forms
The hello world program begins it's life as a high level C program, this is because it's human readable code. For the program to be able to run on a system, each individual statement must be translated into /machine-language/ instructions. These instructions then need to be packaged into a /executable object program/ and then stored as a binary. These object programs can also be referred to as an /executable object/.

The translation form source code to object file in UNIX systems are done by something called a /compiler driver/.
~linux> gcc -o helloWorld main.c~
In the above the gcc compiler will read our source file ~main.c~ and translate it to an executable object called ~helloWorld~. This translation can be represented by the figure bellow
#+CAPTION: The compilation system
[[./imgs/figure1.3.png]]
The whole process is done by four separate programs: the /preprocessor/, /compiler/, /assembler/ and /linker/, in that order. This collective process is called the compilation system.
*** /Preprocessing phase/
  The preprocessor (cpp) will make changes to the original program according to commands that begin with ~#~. For example the ~#include <stdio.h>~ command will instruct the preprocessor to read the contents of the system header file ~stdio.h~ and insert it into the program text, resulting in a new program that typically has the ~.i suffix.
*** /Compilation phase/

  The compiler (cc1) will translate ~helloWorld.i~ into ~helloWorld.s~. ~helloWorld.s~ will contain an assembly language program. This file wil contain a definition of main in assembly that could look like the below (depending on the machine and its architecture):
#+begin_src asm
    main:
        subq $8, %rsp
        movl $.LCO, %edi
        call puts
        movl $0, %eax
        addq $8, %rsp
        ret
#+end_src

Each of the lines above correspond to low-level machine language instructions. Assembly language is useful as it serves as a targget for many comiled languages as a common output. For example, C and Fortran compilers both generate files in the same assembly language.
*** /Linking phase/
Our file makes use of code that is not present in our source program, for example the ~printf~ function resides in a seperate precompiled object called ~printf.o~. This code must somehow be merged into our ~helloWorld.o~ program, The linker (ld) is responsible for this merging step. The result then is our ~helloWorld~ file that is an executable that is ready to be loaded into memory and executed by the system.
* 1.3 It pays to understand how compilation systems work
Some important reasons for understanding the compilation system are:
- /Optimising program/. Knowing how some statements are faster then others and why. Knowing how structuring the code can impact the efficiency of the program.
- /Understanding Link-time errors/. Why do they happen and how can they be fixed. Why does it happen only during runtime sometimes.
- /Avoiding security holes/. Understanding why buffer overflow works and how it can lead to security flaws.
* 1.4 Processors read and interpret instructions stored in memory
Now the hello our ~main.c~ source code has been translated by the compilation system into an executable object. To run it in an unix system we type the following in the shell (a program in of it self)
#+begin_src
>>> ./helloWorld
hello world
>>>
#+end_src
** 1.4.1 Hardware organisation of a system
The following illustration will help understand the typical organisation of a system
#+CAPTION: Hardware organisation of a typical system
[[./imgs/figure1.4.png]]
*** Buses
Buses are a collection of electrical conduits that carry bytes of information back and forth between components. Buses are designed to transfer fixed-sized chunks of bytes called /words/. The /word size/ (the number of bytes a word contains) is system dependent and known as a system parameter. Most machines now have a word size of either 4 bytes (on 32 bit machines) or 8 bytes (on 64 bit machines).
*** I/O Devices
Input/output (I/O) devices are the systems connections to the external world. In the example above it's the mouse, keyboard, display and disk.
The I/O devices are connected to the I/O bus by either a /controller/ or an /adaptor/. The main difference between a controller and an adaptor is how it's packaged. A controller is a chip in either the device itself or on the systems main printed circuit board (usually called a motherboard). An adaptor is a card that is plugged into a slot on the motherboard.
*** Main memory
The main memory is a temporary storage device that holds programs and the data that they manipulate. Main memory consists of a collection /dynamic random access memory/ (DRAM) chips. Memory is organised as a linear array of bytes. Each byte has it's own unique address (an array index) starting from zero. Generally, each machine instructions that makes a program may have any number of bytes. The sizes of data of a C program vary depending on their type. For example on a typical x86-64 machine running linux the types int and float are four bytes long.
*** Processor
The /central processing unit/ (CPU), also known as the processor is what interprets (/executes/) instructions stored in memory. It contains a word sized storage device at it's core known as the /program counter/ (PC.) The program counter will point to (contains the address of) some machine instruction in main memory.

From the point that the system is powered on to the point it is powered off the programmer processor will execute instructions that are pointed at by the program counter and will update the program counter to point to the next instruction. A processors instruction execution model is defined by it's /instruction set architecture/. The sequence described by the model is the following:
Read instruction from memory that is pointed at by the program counter -> Interpret the bits in the instruction -> Perform simple operation represented by instruction -> Update the program counter to point to next instruction
These instructions in memory may or may not be contiguous.

The number of operations are limited and revolve around main memory, the /register file/, and the /arithmetic/logic unit/ (ALU). Th register file is a small storage device made up of a collection of word sized register, each of these registers have a unique name. The arithmetic/logic unit computes new data and address values. Some examples of these simple operations are:
- Load: Copy a byte or word from memory into a register and overwrite it's previous contents
- Store: Copy a byte or word from a register and store it in memory overwriting it's previous content
- Operate: Copy the contents of two registers to the arithmetic/logic unit, perform arithmetic operation on them and store the result in a register overwriting it's previous content.
- Jump: Extract a word from the instruction and copy into the program counter overwriting the program counter's previous content.

In reality the process in much more complicated than this. Modern processors use complicated mechanisms to speed up the execution. A distinction has to be made between a processor's instruction set architecture and it's /microarchitecture/. The processor instruction set architecture describes the effect of each machine code instruction, the microarchitecture describes how the processor is actually made.
** 1.4.2 Running the hello world program
Now we understand that when a user types into the shell the command to run the program the shell loads the executable files via a series of instructions that copies the program's code and data from disk to main memory. The data of the program includes  the string of characters ~hello world\n~ that will be printed out.

/Direct memory access/ is a technique that allows for the system to pass data from disk to memory  without having to pass through the processor.

When the code and data are present in memory the processor will begin to execute the machine instruction of the program' ~main~ routine. The instructions will copy the bytes in the ~hello world\n~ string from memory to the register file and then from there to the display device where the user will then be able to see it.
Here's a figure outlining this process
#+CAPTION: Reading the hello command from the keyboard
[[./imgs/figure1.5.png]]
#+CAPTION: Loading the executable from disk into main memory
[[./imgs/figure1.6.png]]
#+CAPTION: Writing the output string from memory to the display
[[./imgs/figure1.7.png]]
* 1.5 Caches matter
Systems spend a lot of time moving memory around. Instructions for a program are stored on disk memory along with their data. The program and it's data needs to move to main memory and from there it needs to move into the processor so that it can execute it and the data needs to move from memory to the display device. Much of this process gets in the way of the processor doing the real work it needs to do. Due to this system designers have a big concern to make these copying operations faster.

Because of physics, larger storage devices are slower then smaller ones, and the faster storage are cheaper to make then the smaller counterparts. A systems storage device might be 1000 times larger then main memory but might also be 10000 slower to access. But a processor might be able to read data from a register 100 times faster then main memory. This is called the /processor-memory/ gap and it's being getting worse as improvements to semiconductor tech have been made.

A solution to this problem has been the introduction of /cache memories/. These are storage devices that are much smaller but also much faster then any other storage device on the system. They serve as momentary staging areas for information that the processor are likely to need.
#+CAPTION: Cache memory
[[./imgs/figure1.8.png]]
An L1 cache on the processor can be accessed nearly as fast as a register can and can hold ten of thousands of bytes. A larger L2 cache can hold hundreds of thousands to millions bytes and can be 5 times slower then L1 cache. L2 memory is connected to the processor via a special bus. Even though it can take longer to access  then L1 cache it's still much faster then having to reach out to main memory. L1 and L2 caches are implemented using a technology called /static random access memory/ (SRAM). You can even find L3 cache in some models. The idea of this innovation is that systems can take advantage of very large memory and very fast memory by exploiting locality.
* 1.6 Storage devices form a hierarchy
This idea of having smaller and faster memory between the processor and larger and slower memory is a general one. This creates a hierarchy of memory in systems, with smaller but faster memory at the top and slower and larger at the bottom.
#+CAPTION: An example of a memory hierarchy
[[./imgs/figure1.9.png]]
Registers occupy the top level of this hierarchy and is known as level 0 or L0.

This memory hierarchy serves as a way to cache memory for the next level. So main memory serves as a cache for disk storage, L3 serves as a cache for L2, L2 serves as a cache for L1.
* 1.7 The operating system manages the hardware
In the ~helloWorld~ program, when users load our program using the shell and it prints the it's message neither of these two programs accessed any of the hardware involved (keyboard, display, disk or main memory). This is done by the operating system. The operating system can be thought of as a layer of software  in between the application program and the hardware.
#+CAPTION: An example of a memory hierarchy
[[./imgs/figure1.10.png]]
Any attempt to by a program to manipulate the hardware must go through the operating system.

The operating system two primary purpose is to prevent run away programs form misusing the hardware and to provide applications simple and uniform ways to access and manipulate the hardware which often vary. The operating system achieves this by a fundamental abstraction of /processes/, /virtual memory/ and /files/.
#+CAPTION: Abstraction provided by an operating system
[[./imgs/figure1.11.png]]
Files are an abstraction for input/output devices. Virtual memory is an abstraction for disk storage and main memory. Processes are an abstraction for processor, main memory and input/output devices.
** 1.7.1 Processes
When a program is running in a system the operating system gives the illusion that it is the only program running. It gives the illusion that the program is the only one with access to processor, main memory and I/O devices. There's an illusion that the program is the only thing being executed by the processor without interruption and only it's the only object within main memory. This is the abstraction called a process.

With this idea of a process programs can run concurrently while having the illusion of having exclusive use of the hardware. In most system there are more processes that need to be run then there are processor and so in reality, this notion of /concurrency/ is more like interleaving of many processes instructions.
Originally  systems could only execute one program at a time, while /multi-core/ processors can appear to execute multiple processes at the same time by having the processor switch between them. Weather it's a multi-core computer or not systems can appear to be executing multiple programs by interleaving instructions, this is called /context switching/. The model of a /uniprocessor system/ is much simpler so it's the model used to describe concepts for now.

The OS keeps track of all the state a process needs, this state is called the /context/. The context contains the current values of the program counter, the register file and the contents of main memory. When the operating systems decides to transfer the control of one process to another it performs a /context switch/, it saves the context of the currently running program, restores the context of the next process it will run and passes the control to the next process.
#+CAPTION: Process context switching
[[./imgs/figure1.12.png]]
The transition of one process to another is performed by the OS /kernel/. The kernel is the portion of the OS that always in memory. Applications can then execute special /system call/ instructions that will transfer execution to the kernel to perform some task and then returns back to the application. The kernel is not a separate process, it is a collection of code and data structures that the system uses to manage all the processes.
** 1.7.2 Threads
In modern systems a process can consist of multiple execution units, /threads/, each running in the context of the same process and sharing the same code and global  data.
** 1.7.3 Virtual memory
Virtual memory is the abstraction that gives processes the illusion that they have exclusive access to main memory. Every process has the same view of memory know as the /virtual address space/
#+CAPTION: Process virtual address space (not drawn to scale)
[[./imgs/figure1.13.png]]
The virtual address space seen by each process consists of well defined areas, each with a specific purpose:
- /Program code and data/: Code begins at the same fixed address for all processes, followed by data locations that corresponds to global C variables.
- Heap: The /runtime heap/ area is an area that can expand and contract dynamically during the run time. This expansion and contraction is the outcome of running routines such as ~malloc~ and ~free~.
- Shared library: Space that holds data and code for shared libraries, like the C standard library and the mach library.
- Stack: The /user stack/ is used by the compiler to implement function calls. The stack can also grow and shrink like the heap, but it grows when a function is called and shrinks when a function returns.
- Kernel virtual memory: An address space reserved by the kernel. Processes can't read nor write to this space, it can't call functions in this space either. Process must invoke the kernel to perform these operations.
** 1.7.4 Files
Files are a sequence of bytes. Every I/O operation are modelled as a file. We can access input and output by reading and writing files using a set of system calls known as /Unix I/O/.
* 1.8 Systems communicate with other systems using networks
Most modern operating systems are often linked to other systems by networks. From the point of view of a system the network can also be viewed as another I/O device.
#+CAPTION: A network is another I/O device
[[./imgs/figure1.14.png]]
* 1.9 Important themes
** Amdahl's law
Gene Amdahl, a pioneer in the early days of computing, made an observation about the effectiveness of improving performance of one part of the system, this observation is called Amdahl's law. It states that when you speed up one part of a system the effect on the overall system performance depends on how significant this part was and how much it was sped up. Lets say we have a program that takes T_{old} time to execute. Then lets say some part of the system requires a fraction \alpha of this time and we improve it's performance by a factor of k. That is the component originally required time $\alpha T_{old}$, and now it requires $\alpha T_{old}∕k$. The overall execution time would then be

$$
T_{new} = (1 - \alpha) + \alpha T_{old}∕k
= T_{old} [(1 - \alpha) + \alpha∕k]
$$

From this we can compute the speedup S = 𝑇_{old}/𝑇_{new} as

$$
                S = \frac{1}{(1-\alpha) + \alpha/k}
$$

